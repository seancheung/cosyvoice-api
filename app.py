# Copyright (c) 2024 Alibaba Inc (authors: Xiang Lyu, Liu Yue)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import sys
import argparse
import numpy as np
import torch
import torchaudio
import random
import librosa
import base64
import io
import gradio as gr
import logging
from typing import Optional, Tuple, Generator
from scipy.io.wavfile import write
import datetime
import time

# é…ç½®æ—¥å¿—çº§åˆ« - å¯é€‰æ‹©: DEBUG, INFO, WARNING, ERROR, CRITICAL
logging.basicConfig(
    level=logging.INFO,  # ä¿®æ”¹è¿™é‡Œæ¥è®¾ç½®æ—¥å¿—çº§åˆ«
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# è®¾ç½®ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—çº§åˆ«
logging.getLogger('matplotlib').setLevel(logging.WARNING)
logging.getLogger('gradio').setLevel(logging.WARNING)

ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append('{}/CosyVoice'.format(ROOT_DIR))
sys.path.append('{}/CosyVoice/third_party/Matcha-TTS'.format(ROOT_DIR))
from CosyVoice.cosyvoice.cli.cosyvoice import AutoModel
from CosyVoice.cosyvoice.utils.file_utils import load_wav
from CosyVoice.cosyvoice.utils.common import set_all_random_seed

# å…¨å±€å˜é‡
cosyvoice = None
max_val = 0.8
prompt_sr = 16000
output_dir = "outputs"  # é»˜è®¤è¾“å‡ºç›®å½•

def postprocess(speech, top_db=60, hop_length=220, win_length=440):
    """åå¤„ç†ç”Ÿæˆçš„éŸ³é¢‘"""
    speech, _ = librosa.effects.trim(
        speech, top_db=top_db,
        frame_length=win_length,
        hop_length=hop_length
    )
    if speech.abs().max() > max_val:
        speech = speech / speech.abs().max() * max_val
    speech = torch.concat([speech, torch.zeros(1, int(cosyvoice.sample_rate * 0.2))], dim=1)
    return speech

def numpy_to_mp3_bytes(audio_array: np.ndarray, sample_rate: int) -> bytes:
    """
    å°†numpyéŸ³é¢‘æ•°ç»„è½¬æ¢ä¸ºMP3å­—èŠ‚æµï¼Œç”¨äºGradioæµå¼éŸ³é¢‘
    
    Args:
        audio_array: éŸ³é¢‘æ•°æ®æ•°ç»„
        sample_rate: é‡‡æ ·ç‡
        
    Returns:
        MP3æ ¼å¼çš„å­—èŠ‚æµ
    """
    # ç¡®ä¿éŸ³é¢‘æ•°æ®åœ¨æ­£ç¡®çš„èŒƒå›´å†…
    if audio_array.dtype != np.int16:
        # å°†floatéŸ³é¢‘è½¬æ¢ä¸ºint16
        audio_array = (audio_array * 32767).astype(np.int16)
    
    # åˆ›å»ºå†…å­˜ç¼“å†²åŒº
    buffer = io.BytesIO()
    
    # å†™å…¥WAVæ ¼å¼åˆ°ç¼“å†²åŒº
    write(buffer, sample_rate, audio_array)
    
    # è·å–å­—èŠ‚æ•°æ®
    buffer.seek(0)
    audio_bytes = buffer.getvalue()
    
    return audio_bytes

def generate_unique_filename(base_name: str, extension: str = ".wav") -> str:
    """
    ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åï¼Œé¿å…é‡å¤
    
    Args:
        base_name: åŸºç¡€æ–‡ä»¶å
        extension: æ–‡ä»¶æ‰©å±•å
        
    Returns:
        å”¯ä¸€çš„æ–‡ä»¶å
    """
    global output_dir
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(output_dir, exist_ok=True)
    
    # ä½¿ç”¨æ—¶é—´æˆ³ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    microseconds = int(time.time() * 1000000) % 1000000  # å¾®ç§’ç²¾åº¦
    
    filename = f"{base_name}_{timestamp}_{microseconds:06d}{extension}"
    filepath = os.path.join(output_dir, filename)
    
    # å¦‚æœæ–‡ä»¶ä»ç„¶å­˜åœ¨ï¼ˆæå°æ¦‚ç‡ï¼‰ï¼Œæ·»åŠ è®¡æ•°å™¨
    counter = 1
    while os.path.exists(filepath):
        filename = f"{base_name}_{timestamp}_{microseconds:06d}_{counter}{extension}"
        filepath = os.path.join(output_dir, filename)
        counter += 1
    
    return filepath

def save_audio_to_file(audio_data: Tuple[int, np.ndarray], mode: str, tts_text: str) -> str:
    """
    ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°æ–‡ä»¶
    
    Args:
        audio_data: (sample_rate, audio_array) éŸ³é¢‘æ•°æ®
        mode: æ¨ç†æ¨¡å¼
        tts_text: åˆæˆçš„æ–‡æœ¬ï¼ˆä¸å†ç”¨äºæ–‡ä»¶åï¼‰
        
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    sample_rate, audio_array = audio_data
    
    # æ ¹æ®æ¨¡å¼åˆ›å»ºåŸºç¡€æ–‡ä»¶åï¼ˆåªåŒ…å«æ¨¡å¼ï¼Œä¸åŒ…å«æ–‡æœ¬ï¼‰
    mode_map = {
        "3sæé€Ÿå¤åˆ»": "zero_shot",
        "è·¨è¯­ç§å¤åˆ»": "cross_lingual", 
        "è‡ªç„¶è¯­è¨€æ§åˆ¶": "instruct"
    }
    mode_short = mode_map.get(mode, "unknown")
    
    base_name = f"cosyvoice_{mode_short}"
    
    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶è·¯å¾„
    filepath = generate_unique_filename(base_name)
    
    # ç¡®ä¿éŸ³é¢‘æ•°æ®æ ¼å¼æ­£ç¡®
    if audio_array.dtype != np.int16:
        # å°†floatéŸ³é¢‘è½¬æ¢ä¸ºint16
        audio_array = (audio_array * 32767).astype(np.int16)
    
    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
    write(filepath, sample_rate, audio_array)
    
    logging.info(f"éŸ³é¢‘å·²ä¿å­˜åˆ°: {filepath}")
    return filepath

def generate_audio(
    tts_text: str,
    prompt_audio: Optional[str],
    prompt_text: str,
    mode: str,
    instruct_text: str = "",
    seed: Optional[int] = None,
    speed: float = 1.0,
    streaming: bool = False
) -> Tuple[Optional[Tuple], str]:
    """
    ç”ŸæˆéŸ³é¢‘çš„ä¸»å‡½æ•°
    
    Args:
        tts_text: è¦åˆæˆçš„æ–‡æœ¬
        prompt_audio: æç¤ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        prompt_text: æç¤ºæ–‡æœ¬
        mode: æ¨ç†æ¨¡å¼
        instruct_text: æŒ‡ä»¤æ–‡æœ¬ï¼ˆè‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼ä½¿ç”¨ï¼‰
        seed: éšæœºç§å­
        speed: è¯­é€Ÿæ§åˆ¶
        streaming: æ˜¯å¦ä½¿ç”¨æµå¼ç”Ÿæˆ
        
    Returns:
        Tuple[audio_tuple, message]
        audio_tuple: (sample_rate, audio_array) æˆ– None
        message: çŠ¶æ€ä¿¡æ¯å­—ç¬¦ä¸²
    """
    global cosyvoice
    
    try:
        # éªŒè¯è¾“å…¥
        if not tts_text or tts_text.strip() == "":
            return None, "âŒ é”™è¯¯: è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬"
            
        if not prompt_audio:
            return None, "âŒ é”™è¯¯: è¯·ä¸Šä¼ æç¤ºéŸ³é¢‘æ–‡ä»¶"
            
        # æ£€æŸ¥promptæ–‡æœ¬
        if prompt_text.strip() == "" and mode in ['3sæé€Ÿå¤åˆ»', 'è‡ªç„¶è¯­è¨€æ§åˆ¶', 'è·¨è¯­ç§å¤åˆ»']:
            return None, "âŒ é”™è¯¯: è¯¥æ¨¡å¼éœ€è¦æä¾›æç¤ºæ–‡æœ¬"
            
        # æ£€æŸ¥æŒ‡ä»¤æ–‡æœ¬
        if mode == 'è‡ªç„¶è¯­è¨€æ§åˆ¶' and instruct_text.strip() == "":
            return None, "âŒ é”™è¯¯: è‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼éœ€è¦æä¾›æŒ‡ä»¤æ–‡æœ¬"
        
        # æ£€æŸ¥éŸ³é¢‘é‡‡æ ·ç‡
        audio_info = torchaudio.info(prompt_audio)
        if audio_info.sample_rate < prompt_sr:
            return None, f"âŒ é”™è¯¯: æç¤ºéŸ³é¢‘é‡‡æ ·ç‡ {audio_info.sample_rate} ä½äºè¦æ±‚çš„ {prompt_sr} Hz"
        
        # è®¾ç½®éšæœºç§å­
        if seed is None:
            seed = random.randint(1, 100000000)
        set_all_random_seed(seed)
        
        result_audio = None
        
        # æ ¹æ®æ¨¡å¼è¿›è¡Œæ¨ç† - ç›´æ¥ä¼ é€’éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        if mode == '3sæé€Ÿå¤åˆ»':
            logging.info('æ‰§è¡Œé›¶æ ·æœ¬æ¨ç†')
            for i in cosyvoice.inference_zero_shot(tts_text, prompt_text, prompt_audio, stream=streaming, speed=speed):
                audio = i['tts_speech'].numpy().flatten()
                if result_audio is None:
                    result_audio = audio
                else:
                    result_audio = np.concatenate([result_audio, audio])
                    
        elif mode == 'è·¨è¯­ç§å¤åˆ»':
            logging.info('æ‰§è¡Œè·¨è¯­è¨€æ¨ç†')
            for i in cosyvoice.inference_cross_lingual(tts_text, prompt_audio, stream=streaming, speed=speed):
                audio = i['tts_speech'].numpy().flatten()
                if result_audio is None:
                    result_audio = audio
                else:
                    result_audio = np.concatenate([result_audio, audio])
                    
        elif mode == 'è‡ªç„¶è¯­è¨€æ§åˆ¶':
            logging.info('æ‰§è¡ŒæŒ‡ä»¤æ¨ç†')
            for i in cosyvoice.inference_instruct2(tts_text, instruct_text, prompt_audio, stream=streaming, speed=speed):
                audio = i['tts_speech'].numpy().flatten()
                if result_audio is None:
                    result_audio = audio
                else:
                    result_audio = np.concatenate([result_audio, audio])
        
        if result_audio is not None:
            audio_data = (cosyvoice.sample_rate, result_audio)
            
            # è‡ªåŠ¨ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            try:
                saved_path = save_audio_to_file(audio_data, mode, tts_text)
                return audio_data, f"âœ… éŸ³é¢‘ç”ŸæˆæˆåŠŸï¼ä½¿ç”¨ç§å­: {seed}\nğŸ’¾ å·²ä¿å­˜åˆ°: {saved_path}"
            except Exception as e:
                logging.warning(f"ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
                return audio_data, f"âœ… éŸ³é¢‘ç”ŸæˆæˆåŠŸï¼ä½¿ç”¨ç§å­: {seed}\nâš ï¸ ä¿å­˜å¤±è´¥: {str(e)}"
        else:
            return None, "âŒ é”™è¯¯: éŸ³é¢‘ç”Ÿæˆå¤±è´¥"
            
    except Exception as e:
        error_msg = f"âŒ ç”ŸæˆéŸ³é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        logging.error(error_msg)
        return None, error_msg

def generate_audio_streaming_with_complete(
    tts_text: str,
    prompt_audio: Optional[str],
    prompt_text: str,
    mode: str,
    instruct_text: str = "",
    seed: Optional[int] = None,
    speed: float = 1.0
) -> Generator[Tuple[Optional[bytes], Optional[Tuple], str], None, None]:
    """
    æ”¹è¿›çš„æµå¼éŸ³é¢‘ç”Ÿæˆå‡½æ•° - åŒæ—¶æ”¯æŒæµå¼æ’­æ”¾å’Œå®Œæ•´éŸ³é¢‘
    
    Args:
        tts_text: è¦åˆæˆçš„æ–‡æœ¬
        prompt_audio: æç¤ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        prompt_text: æç¤ºæ–‡æœ¬
        mode: æ¨ç†æ¨¡å¼
        instruct_text: æŒ‡ä»¤æ–‡æœ¬ï¼ˆè‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼ä½¿ç”¨ï¼‰
        seed: éšæœºç§å­
        speed: è¯­é€Ÿæ§åˆ¶
        
    Yields:
        Tuple[streaming_bytes, complete_audio, message]: 
        - streaming_bytes: æµå¼æ’­æ”¾çš„éŸ³é¢‘ç‰‡æ®µå­—èŠ‚æµ
        - complete_audio: å®Œæ•´éŸ³é¢‘(sample_rate, audio_array)æˆ–None
        - message: çŠ¶æ€ä¿¡æ¯
    """
    global cosyvoice
    
    try:
        # éªŒè¯è¾“å…¥
        if not tts_text or tts_text.strip() == "":
            yield None, None, "âŒ é”™è¯¯: è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬"
            return
            
        if not prompt_audio:
            yield None, None, "âŒ é”™è¯¯: è¯·ä¸Šä¼ æç¤ºéŸ³é¢‘æ–‡ä»¶"
            return
            
        # æ£€æŸ¥promptæ–‡æœ¬
        if prompt_text.strip() == "" and mode in ['3sæé€Ÿå¤åˆ»', 'è‡ªç„¶è¯­è¨€æ§åˆ¶', 'è·¨è¯­ç§å¤åˆ»']:
            yield None, None, "âŒ é”™è¯¯: è¯¥æ¨¡å¼éœ€è¦æä¾›æç¤ºæ–‡æœ¬"
            return
            
        # æ£€æŸ¥æŒ‡ä»¤æ–‡æœ¬
        if mode == 'è‡ªç„¶è¯­è¨€æ§åˆ¶' and instruct_text.strip() == "":
            yield None, None, "âŒ é”™è¯¯: è‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼éœ€è¦æä¾›æŒ‡ä»¤æ–‡æœ¬"
            return
        
        # æ£€æŸ¥éŸ³é¢‘é‡‡æ ·ç‡
        audio_info = torchaudio.info(prompt_audio)
        if audio_info.sample_rate < prompt_sr:
            yield None, None, f"âŒ é”™è¯¯: æç¤ºéŸ³é¢‘é‡‡æ ·ç‡ {audio_info.sample_rate} ä½äºè¦æ±‚çš„ {prompt_sr} Hz"
            return
        
        # è®¾ç½®éšæœºç§å­
        if seed is None:
            seed = random.randint(1, 100000000)
        set_all_random_seed(seed)
        
        chunk_count = 0
        accumulated_audio = None
        
        # æ ¹æ®æ¨¡å¼è¿›è¡Œæµå¼æ¨ç† - ç›´æ¥ä¼ é€’éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        inference_generator = None
        if mode == '3sæé€Ÿå¤åˆ»':
            logging.info('æ‰§è¡Œé›¶æ ·æœ¬æµå¼æ¨ç†')
            inference_generator = cosyvoice.inference_zero_shot(tts_text, prompt_text, prompt_audio, stream=True, speed=speed)
                    
        elif mode == 'è·¨è¯­ç§å¤åˆ»':
            logging.info('æ‰§è¡Œè·¨è¯­è¨€æµå¼æ¨ç†')
            inference_generator = cosyvoice.inference_cross_lingual(tts_text, prompt_audio, stream=True, speed=speed)
                    
        elif mode == 'è‡ªç„¶è¯­è¨€æ§åˆ¶':
            logging.info('æ‰§è¡ŒæŒ‡ä»¤æµå¼æ¨ç†')
            inference_generator = cosyvoice.inference_instruct2(tts_text, instruct_text, prompt_audio, stream=True, speed=speed)
        
        if inference_generator:
            for i in inference_generator:
                audio_chunk = i['tts_speech'].numpy().flatten()
                chunk_count += 1
                
                # ç´¯ç§¯éŸ³é¢‘ç‰‡æ®µç”¨äºå®Œæ•´éŸ³é¢‘
                if accumulated_audio is None:
                    accumulated_audio = audio_chunk
                else:
                    accumulated_audio = np.concatenate([accumulated_audio, audio_chunk])
                
                # è½¬æ¢éŸ³é¢‘ç‰‡æ®µä¸ºå­—èŠ‚æµï¼ˆç”¨äºæµå¼æ’­æ”¾ï¼‰
                audio_bytes = numpy_to_mp3_bytes(audio_chunk, cosyvoice.sample_rate)
                
                # yieldæµå¼éŸ³é¢‘ç‰‡æ®µï¼Œå®Œæ•´éŸ³é¢‘è¿˜æ²¡å‡†å¤‡å¥½
                yield audio_bytes, None, f"ğŸ”Š æ­£åœ¨ç”Ÿæˆ... ç‰‡æ®µ {chunk_count} (ç§å­: {seed})"
        
        # æœ€ç»ˆå®Œæˆ - æä¾›å®Œæ•´çš„ç´¯ç§¯éŸ³é¢‘å¹¶è‡ªåŠ¨ä¿å­˜
        if accumulated_audio is not None:
            complete_audio = (cosyvoice.sample_rate, accumulated_audio)
            
            # è‡ªåŠ¨ä¿å­˜å®Œæ•´éŸ³é¢‘æ–‡ä»¶
            try:
                saved_path = save_audio_to_file(complete_audio, mode, tts_text)
                yield None, complete_audio, f"âœ… æµå¼éŸ³é¢‘ç”Ÿæˆå®Œæˆï¼å…± {chunk_count} ä¸ªç‰‡æ®µ (ç§å­: {seed})\nğŸ’¾ å·²ä¿å­˜åˆ°: {saved_path}"
            except Exception as e:
                logging.warning(f"ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
                yield None, complete_audio, f"âœ… æµå¼éŸ³é¢‘ç”Ÿæˆå®Œæˆï¼å…± {chunk_count} ä¸ªç‰‡æ®µ (ç§å­: {seed})\nâš ï¸ ä¿å­˜å¤±è´¥: {str(e)}"
        else:
            yield None, None, "âŒ é”™è¯¯: æµå¼éŸ³é¢‘ç”Ÿæˆå¤±è´¥"
            
    except Exception as e:
        error_msg = f"âŒ æµå¼ç”ŸæˆéŸ³é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        logging.error(error_msg)
        yield None, None, error_msg

def generate_audio_streaming(
    tts_text: str,
    prompt_audio: Optional[str],
    prompt_text: str,
    mode: str,
    instruct_text: str = "",
    seed: Optional[int] = None,
    speed: float = 1.0
) -> Generator[Tuple[bytes, str], None, None]:
    """ä¿ç•™åŸæœ‰çš„çº¯æµå¼å‡½æ•°ä»¥ä¾¿å…¼å®¹"""
    for streaming_bytes, complete_audio, message in generate_audio_streaming_with_complete(
        tts_text, prompt_audio, prompt_text, mode, instruct_text, seed, speed
    ):
        if streaming_bytes is not None:
            yield streaming_bytes, message

def create_gradio_interface():
    """åˆ›å»º Gradio ç•Œé¢"""
    
    # è‡ªå®šä¹‰ CSS
    custom_css = """
    .gradio-container {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    .main-header {
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        color: #2563eb;
        font-weight: bold;
        margin: 1rem 0;
    }
    """
    
    with gr.Blocks(css=custom_css, title="CosyVoice è¯­éŸ³åˆæˆ", theme=gr.themes.Soft()) as interface:
        
        # æ ‡é¢˜å’Œè¯´æ˜
        gr.HTML("""
        <div class="main-header">
            <h1>ğŸµ CosyVoice è¯­éŸ³åˆæˆç³»ç»Ÿ</h1>
            <p>åŸºäºæ·±åº¦å­¦ä¹ çš„å¤šæ¨¡æ€è¯­éŸ³åˆæˆï¼Œæ”¯æŒé›¶æ ·æœ¬ã€è·¨è¯­è¨€å’ŒæŒ‡ä»¤æ§åˆ¶</p>
        </div>
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                # è¾“å…¥åŒºåŸŸ
                gr.HTML('<h3 class="section-header">ğŸ“ è¾“å…¥è®¾ç½®</h3>')
                
                tts_text = gr.Textbox(
                    label="åˆæˆæ–‡æœ¬",
                    placeholder="è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬å†…å®¹...",
                    lines=3,
                    max_lines=5
                )
                
                prompt_audio = gr.Audio(
                    label="æç¤ºéŸ³é¢‘ (ä¸Šä¼ å‚è€ƒéŸ³é¢‘ï¼Œç”¨äºå£°éŸ³å…‹éš†)",
                    type="filepath"
                )
                
                prompt_text = gr.Textbox(
                    label="æç¤ºæ–‡æœ¬ (æç¤ºéŸ³é¢‘å¯¹åº”çš„æ–‡å­—å†…å®¹ï¼Œé›¶æ ·æœ¬å’Œè·¨è¯­è¨€æ¨¡å¼å¿…å¡«)",
                    placeholder="è¾“å…¥æç¤ºéŸ³é¢‘å¯¹åº”çš„æ–‡æœ¬å†…å®¹...",
                    lines=2
                )
                
                mode = gr.Dropdown(
                    choices=["3sæé€Ÿå¤åˆ»", "è·¨è¯­ç§å¤åˆ»", "è‡ªç„¶è¯­è¨€æ§åˆ¶"],
                    value="3sæé€Ÿå¤åˆ»",
                    label="æ¨ç†æ¨¡å¼ (é€‰æ‹©è¯­éŸ³åˆæˆæ¨¡å¼)"
                )
                
                instruct_text = gr.Textbox(
                    label="æŒ‡ä»¤æ–‡æœ¬ (è‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼çš„æŒ‡ä»¤ï¼Œä»…åœ¨è¯¥æ¨¡å¼ä¸‹æ˜¾ç¤º)",
                    placeholder="ä¾‹å¦‚ï¼šè¯·ç”¨æ¸©æŸ”çš„è¯­è°ƒæœ—è¯»...",
                    lines=2,
                    visible=False
                )
                
                streaming_mode = gr.Checkbox(
                    label="ğŸ”Š æµå¼æ’­æ”¾æ¨¡å¼ (è¾¹ç”Ÿæˆè¾¹æ’­æ”¾ï¼Œå®æ—¶é¢„è§ˆ)",
                    value=False,
                    interactive=True
                )
                
                # é«˜çº§è®¾ç½®
                with gr.Accordion("ğŸ”§ é«˜çº§è®¾ç½®", open=False):
                    with gr.Row():
                        seed = gr.Number(
                            label="éšæœºç§å­ (æ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§)",
                            value=None,
                            precision=0
                        )
                        speed = gr.Slider(
                            minimum=0.5,
                            maximum=2.0,
                            value=1.0,
                            step=0.1,
                            label="è¯­é€Ÿ (è°ƒèŠ‚è¯­éŸ³æ’­æ”¾é€Ÿåº¦)"
                        )
                
                # ç”ŸæˆæŒ‰é’®
                generate_btn = gr.Button(
                    "ğŸš€ å¼€å§‹ç”Ÿæˆ",
                    variant="primary",
                    size="lg"
                )
                
            with gr.Column(scale=1):
                # è¾“å‡ºåŒºåŸŸ
                gr.HTML('<h3 class="section-header">ğŸ”Š ç”Ÿæˆç»“æœ</h3>')
                
                # æµå¼éŸ³é¢‘ç»„ä»¶ï¼ˆå®æ—¶æ’­æ”¾ç‰‡æ®µï¼‰
                streaming_audio = gr.Audio(
                    label="ğŸµ æµå¼æ’­æ”¾ï¼ˆå®æ—¶ï¼‰",
                    interactive=False,
                    streaming=True,  # å¯ç”¨æµå¼éŸ³é¢‘æ”¯æŒ
                    autoplay=True,   # è‡ªåŠ¨æ’­æ”¾æ–°çš„éŸ³é¢‘ç‰‡æ®µ
                    visible=False    # é»˜è®¤ä¸æ˜¾ç¤ºï¼Œæ ¹æ®æ¨¡å¼åˆ‡æ¢
                )
                
                # æ™®é€šéŸ³é¢‘ç»„ä»¶ï¼ˆå®Œæ•´éŸ³é¢‘ï¼‰
                output_audio = gr.Audio(
                    label="ğŸ“„ å®Œæ•´éŸ³é¢‘",
                    interactive=False,
                    streaming=False  # æ™®é€šéŸ³é¢‘ç»„ä»¶
                )
                
                output_message = gr.Textbox(
                    label="çŠ¶æ€ä¿¡æ¯",
                    lines=3,
                    interactive=False
                )
                
                # é¢„ç½®ç¤ºä¾‹
                with gr.Accordion("ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹", open=False):
                    gr.HTML("""
                    <div style="padding: 1rem; background-color: #f8fafc; border-radius: 0.5rem;">
                        <h4>ä½¿ç”¨è¯´æ˜ï¼š</h4>
                        <ol>
                            <li><strong>3sæé€Ÿå¤åˆ»ï¼š</strong> åŸºäº3ç§’å‚è€ƒéŸ³é¢‘è¿›è¡Œå£°éŸ³å…‹éš†</li>
                            <li><strong>è·¨è¯­ç§å¤åˆ»ï¼š</strong> ä¿æŒéŸ³è‰²è¿›è¡Œè·¨è¯­è¨€åˆæˆ</li>
                            <li><strong>è‡ªç„¶è¯­è¨€æ§åˆ¶ï¼š</strong> é€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ§åˆ¶åˆæˆæ•ˆæœ</li>
                        </ol>
                        <h4>æ’­æ”¾æ¨¡å¼ï¼š</h4>
                        <ul>
                            <li><strong>ğŸ”Š æµå¼æ’­æ”¾æ¨¡å¼ï¼š</strong> 
                                <br>â€¢ <strong>ğŸµ æµå¼æ’­æ”¾</strong>ï¼šå®æ—¶æ’­æ”¾éŸ³é¢‘ç‰‡æ®µï¼Œç«‹å³å¬åˆ°ç”Ÿæˆæ•ˆæœ
                                <br>â€¢ <strong>ğŸ“„ å®Œæ•´éŸ³é¢‘</strong>ï¼šç”Ÿæˆå®Œæˆåæ˜¾ç¤ºå®Œæ•´çš„å¯ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
                            </li>
                            <li><strong>ğŸ“„ æ­£å¸¸æ¨¡å¼ï¼š</strong> åªæ˜¾ç¤ºå®Œæ•´éŸ³é¢‘ï¼Œç”Ÿæˆå®Œæˆåä¸€æ¬¡æ€§æ’­æ”¾</li>
                        </ul>
                        <p><strong>ğŸ’¡ åŒéŸ³é¢‘ä¼˜åŠ¿ï¼š</strong> æµå¼æ¨¡å¼ä¸‹æ—¢èƒ½å®æ—¶é¢„è§ˆï¼Œåˆèƒ½è·å¾—å®Œæ•´çš„éŸ³é¢‘æ–‡ä»¶ï¼</p>
                        <p><strong>ğŸ’¾ è‡ªåŠ¨ä¿å­˜ï¼š</strong> æ‰€æœ‰ç”Ÿæˆçš„å®Œæ•´éŸ³é¢‘éƒ½ä¼šè‡ªåŠ¨ä¿å­˜åˆ°outputsç›®å½•ï¼Œæ–‡ä»¶ååŒ…å«æ¨¡å¼ã€æ–‡æœ¬å’Œæ—¶é—´æˆ³</p>
                        <p><strong>æç¤ºï¼š</strong> è¯·ç¡®ä¿ä¸Šä¼ çš„éŸ³é¢‘è´¨é‡æ¸…æ™°ï¼Œé‡‡æ ·ç‡ä¸ä½äº16kHz</p>
                    </div>
                    """)
        
        # åŠ¨æ€æ˜¾ç¤ºæŒ‡ä»¤æ–‡æœ¬æ¡†
        def update_instruct_visibility(mode_value):
            return gr.update(visible=(mode_value == "è‡ªç„¶è¯­è¨€æ§åˆ¶"))
        
        # åŠ¨æ€æ˜¾ç¤ºæµå¼éŸ³é¢‘ç»„ä»¶
        def update_streaming_audio_visibility(streaming_enabled):
            return gr.update(visible=streaming_enabled)
        
        # ç»Ÿä¸€å¤„ç†éŸ³é¢‘ç”Ÿæˆçš„å‡½æ•°
        def handle_audio_generation(tts_text, prompt_audio, prompt_text, mode, instruct_text, seed, speed, streaming):
            if streaming:
                # æµå¼ç”Ÿæˆæ¨¡å¼ - åŒæ—¶æ›´æ–°æµå¼å’Œæ™®é€šéŸ³é¢‘ç»„ä»¶
                for streaming_bytes, complete_audio, message in generate_audio_streaming_with_complete(
                    tts_text, prompt_audio, prompt_text, mode, instruct_text, seed, speed
                ):
                    yield streaming_bytes, complete_audio, message  # streaming_audio, output_audio, message
            else:
                # æ­£å¸¸ç”Ÿæˆæ¨¡å¼ - åªæ›´æ–°æ™®é€šéŸ³é¢‘ç»„ä»¶
                audio_result, message = generate_audio(
                    tts_text, prompt_audio, prompt_text, mode, instruct_text, seed, speed, streaming=False
                )
                yield None, audio_result, message  # streaming_audio, output_audio, message
        
        mode.change(
            fn=update_instruct_visibility,
            inputs=[mode],
            outputs=[instruct_text]
        )
        
        # æµå¼æ¨¡å¼åˆ‡æ¢äº‹ä»¶
        streaming_mode.change(
            fn=update_streaming_audio_visibility,
            inputs=[streaming_mode],
            outputs=[streaming_audio]
        )
        
        # ç»‘å®šç”ŸæˆæŒ‰é’® - ç°åœ¨è¾“å‡ºåˆ°ä¸‰ä¸ªç»„ä»¶
        generate_btn.click(
            fn=handle_audio_generation,
            inputs=[tts_text, prompt_audio, prompt_text, mode, instruct_text, seed, speed, streaming_mode],
            outputs=[streaming_audio, output_audio, output_message],
            show_progress=True
        )
        
        # ç¤ºä¾‹è¾“å…¥
        gr.Examples(
            examples=[
                [
                    "ä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œæˆ‘ä»¬ä¸€èµ·å»å…¬å›­èµ°èµ°å§ï¼",
                    None,  # è¿™é‡Œéœ€è¦ç”¨æˆ·è‡ªå·±ä¸Šä¼ éŸ³é¢‘
                    "ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨è¯­éŸ³åˆæˆç³»ç»Ÿã€‚",
                    "3sæé€Ÿå¤åˆ»",
                    "",
                    12345,
                    1.0,
                    False  # é»˜è®¤ä¸ä½¿ç”¨æµå¼æ¨¡å¼
                ],
                [
                    "Hello, welcome to the voice synthesis system.",
                    None,
                    "ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨è¯­éŸ³åˆæˆç³»ç»Ÿã€‚",
                    "è·¨è¯­ç§å¤åˆ»", 
                    "",
                    54321,
                    1.0,
                    False
                ],
                [
                    "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚",
                    None,
                    "å‚è€ƒéŸ³é¢‘æ–‡æœ¬",
                    "è‡ªç„¶è¯­è¨€æ§åˆ¶",
                    "è¯·ç”¨æ¸©æŸ”ç”œç¾çš„å£°éŸ³æœ—è¯»",
                    98765,
                    1.0,
                    True  # å±•ç¤ºæµå¼æ¨¡å¼
                ]
            ],
            inputs=[tts_text, prompt_audio, prompt_text, mode, instruct_text, seed, speed, streaming_mode],
        )
    
    return interface

def main():
    parser = argparse.ArgumentParser(description='CosyVoice è¯­éŸ³åˆæˆ Web ç•Œé¢')
    parser.add_argument('--port',
                        type=int,
                        default=7860,
                        help='æœåŠ¡ç«¯å£å·')
    parser.add_argument('--host',
                        type=str,
                        default='127.0.0.1',
                        help='æœåŠ¡ä¸»æœºåœ°å€')
    parser.add_argument('--model-dir',
                        type=str,
                        default='CosyVoice/pretrained_models/CosyVoice3-0.5B',
                        help='æ¨¡å‹è·¯å¾„æˆ– modelscope repo id')
    parser.add_argument('--output-dir',
                        type=str,
                        default='outputs',
                        help='éŸ³é¢‘æ–‡ä»¶è‡ªåŠ¨ä¿å­˜ç›®å½•')
    parser.add_argument('--share',
                        action='store_true',
                        help='åˆ›å»ºå…¬å…±åˆ†äº«é“¾æ¥')
    parser.add_argument('--log-level',
                        type=str,
                        default='INFO',
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
                        help='æ—¥å¿—è¾“å‡ºçº§åˆ«')
    args = parser.parse_args()
    
    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°è®¾ç½®æ—¥å¿—çº§åˆ«
    log_level = getattr(logging, args.log_level.upper())
    logging.getLogger().setLevel(log_level)
    logging.info(f"æ—¥å¿—çº§åˆ«è®¾ç½®ä¸º: {args.log_level}")
    
    global cosyvoice, output_dir
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = args.output_dir
    
    # åˆå§‹åŒ–æ¨¡å‹
    print("ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...")
    try:
        cosyvoice = AutoModel(model_dir=args.model_dir)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        sys.exit(1)
    
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    interface = create_gradio_interface()
    
    print(f"ğŸš€ å¯åŠ¨ Web æœåŠ¡...")
    print(f"ğŸ“ è®¿é—®åœ°å€: http://{args.host}:{args.port}")
    print(f"ğŸ’¾ éŸ³é¢‘ä¿å­˜ç›®å½•: {os.path.abspath(output_dir)}")
    
    interface.launch(
        server_name=args.host,
        server_port=args.port,
        share=args.share,
        show_error=True
    )

if __name__ == '__main__':
    main()
